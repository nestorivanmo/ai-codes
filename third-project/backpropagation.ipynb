{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "outputs": [],
   "source": [
    "def net(w0, W, X):\n",
    "    return (w0 + np.dot(W, X.T))[0]\n",
    "\n",
    "def o(net):\n",
    "    return 1 / (1 + np.e ** (-net))\n",
    "\n",
    "def error(T, Z):\n",
    "    return (0.5*(T[0]-Z[0])**2).sum()\n",
    "\n",
    "def output_hidden_layers(X, HL):\n",
    "    num_layers = HL.shape[0]\n",
    "    print(f\"Input: \\n\\t {X}\")\n",
    "    for i in range(1, num_layers + 1):\n",
    "        if i < num_layers:\n",
    "            print(f\"Hidden layer #{i}: \\n\\t {HL[i-1]}\")\n",
    "            continue\n",
    "        print(f\"Output: \\n\\t {HL[i-1]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(X, W, L, verbose=False):\n",
    "    layers = L.copy()\n",
    "    layers.append(X.shape[1])\n",
    "    layers = np.array(layers)\n",
    "    if layers.shape[0] != W.shape[0]:\n",
    "        raise Exception(\"The length of W should be equal to the number of layers\")\n",
    "    R = []\n",
    "    Yi = X\n",
    "    for idx, neurons in enumerate(layers):\n",
    "        W_matrix = W[idx]\n",
    "        Y_temp = []\n",
    "        for neuron in range(neurons):\n",
    "            Wi = W_matrix[neuron]\n",
    "            net_i = net(Wi[0], Wi[1:], Yi)\n",
    "            Y_temp.append(o(net_i))\n",
    "        Yi = np.array([Y_temp])\n",
    "        R.append(Yi)\n",
    "    if verbose:\n",
    "        output_hidden_layers(X, np.array(R))\n",
    "    return np.array(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0.05, 0.1]])\n",
    "T = np.array([[0.01, 0.99]])\n",
    "hidden_layers = [2]\n",
    "W = np.array([\n",
    "        np.array([\n",
    "            [0.35, 0.15, 0.2],\n",
    "            [0.35, 0.25, 0.3]\n",
    "        ]),\n",
    "        np.array([\n",
    "            [0.6, 0.4, 0.45],\n",
    "            [0.6, 0.5, 0.55]\n",
    "        ])\n",
    "    ])\n",
    "eta = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input: \n\t [[0.05 0.1 ]]\nHidden layer #1: \n\t [[0.59326999 0.59688438]]\nOutput: \n\t [[0.75136507 0.77292847]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.2983711087600027"
      ]
     },
     "metadata": {},
     "execution_count": 399
    }
   ],
   "source": [
    "R = forward_propagate(X, W, hidden_layers, verbose=True)\n",
    "Z = R[-1]\n",
    "E = error(T, Z)\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[0.59326999, 0.59688438]],\n",
       "\n",
       "       [[0.75136507, 0.77292847]]])"
      ]
     },
     "metadata": {},
     "execution_count": 400
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagate(X, R, T, W, eta, hidden_layers, verbose=False):\n",
    "    new_W = W[::-1]\n",
    "    for idx, HL in enumerate(R[::-1]): #HL: hidden layer\n",
    "        #Hidden Layers\n",
    "        if idx < R.shape[0]-1:\n",
    "            new_W[idx][:, 1:] = hidden_layer(HL, T, R, idx, new_W)\n",
    "            continue\n",
    "        initial_weights(X, HL, T, R, idx, new_W, eta)\n",
    "    return new_W\n",
    "\n",
    "def hidden_layer(HL, T, R, idx, W):\n",
    "    d_EZ = HL - T\n",
    "    d_Znet = HL*(1-HL)\n",
    "    alpha = d_EZ * d_Znet\n",
    "    d_netV = R[idx]\n",
    "    d_EV = alpha.T @ d_netV\n",
    "    return W[idx][:, 1:] - (eta * d_EV)\n",
    "\n",
    "def initial_weights(X, HL, T, R, idx, new_W, eta):\n",
    "    curr_W = new_W[1][:,1:]\n",
    "    Y = R[0]\n",
    "    Z = R[1]\n",
    "    V = np.diagonal(new_W[0][:,1:])\n",
    "    deltaE = np.sum(np.outer(V, (Z-T)*(Z*(1-Z))),axis=1)\n",
    "    deltaEW = np.outer(deltaE*Y*(1-Y),X)\n",
    "    new_weights = curr_W - eta*deltaEW\n",
    "    new_W[1][:,1:] = new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[0.6       , 0.35891648, 0.40866619],\n",
       "        [0.6       , 0.51130127, 0.56137012]],\n",
       "\n",
       "       [[0.35      , 0.14978262, 0.19956523],\n",
       "        [0.35      , 0.24966097, 0.29932193]]])"
      ]
     },
     "metadata": {},
     "execution_count": 402
    }
   ],
   "source": [
    "backward_propagate(X, R, T, W, eta, hidden_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}